# ----- App -----
APP_ENV=dev
LOG_LEVEL=INFO

# ----- API -----
API_HOST=0.0.0.0
API_PORT=8000
CORS_ORIGINS=http://localhost:3000

# ----- Database / Redis -----
# Docker Compose (default)
#DATABASE_URL=postgresql://postgres:postgres@db:5432/exam_tutor
#REDIS_URL=redis://redis:6379/0
#Hosted (Supabase + Upstash)
DATABASE_URL=postgresql://postgres:<PASSWORD>@db.<project-ref>.supabase.co:5432/postgres?sslmode=require
REDIS_URL=rediss://default:<PASSWORD>@<host>:<port>/0

# ----- Embeddings -----
# Docker Compose: http://embeddings:8001
# Local run: http://localhost:8001
EMBEDDINGS_BASE_URL=http://embeddings:8001
EMBEDDINGS_MODEL=BAAI/bge-m3
EMBEDDINGS_TIMEOUT_S=60

# ----- Retrieval defaults -----
RETRIEVE_TOP_K=20
RETRIEVE_TOP_N=8
RETRIEVE_MIN_SCORE=0.15
RETRIEVE_EXCLUDE_TAGS=front_matter,boilerplate,image_only,duplicate

# Optional reranker (better relevance; higher latency on CPU)
RERANK_ENABLED=false
RERANK_MODEL=BAAI/bge-reranker-v2-m3
RERANK_TOP_M=30
RERANK_BATCH_SIZE=16

# ----- LLM (vLLM OpenAI-compatible) -----
# Set LLM_MODE=mock for local dev without GPU/vLLM
LLM_MODE=mock
LLM_BASE_URL=http://inference:8002/v1
LLM_MODEL=meta-llama/Llama-3.1-8B-Instruct
LLM_API_KEY=EMPTY
LLM_TIMEOUT_S=120

# ----- Tutor defaults -----
DEFAULT_EXAM=GATE_DA
DEFAULT_MODE=doubt
DEFAULT_LANGUAGE=en

# ----- Chunking -----
TOKENIZER_NAME=Qwen/Qwen2.5-7B-Instruct  # change to your served model tokenizer
CHUNK_MIN_TOKENS=500
CHUNK_MAX_TOKENS=900
CHUNK_OVERLAP_TOKENS=100
CHUNK_PARENT_SECTION_LEVEL=2
CHUNK_FILTER_ENABLED=true
CHUNK_FILTER_MIN_TOKENS=40
CHUNK_FILTER_MAX_CHUNKS_PER_DOC=2000
CHUNK_FILTER_MAX_CHUNKS_PER_PARENT=400

# ----- Storage (MVP local) -----
# For production, replace with S3/GCS and store signed URLs in DB.
LOCAL_DOC_ROOT=./data
